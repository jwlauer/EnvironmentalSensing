{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6226adf5",
   "metadata": {},
   "source": [
    "# Analysis of tipping bucket precipitation counts\n",
    "This notebook illustrates how one can analyze a cumulative count vs. time to derive intensities (i.e., rates at which counts occur over time) within various discrete time intervals. The assumption is that the counts occur each time a given depth of rainfall, here 1/100th of an inch, accumulates.\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d609469-86b0-41ad-adab-7931612ba9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running in a Colab notebook, start the notebook, then remove the hashtags on the following lines\n",
    "#!git clone https://github.com/jwlauer/EnvironmentalSensing.git\n",
    "#%cd EnvironmentalSensing/AnalysisCode/RainfallAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "#Enable interactive figures\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b6546",
   "metadata": {},
   "source": [
    "### Import the data\n",
    "\n",
    "Here, the assumption is that the data has been downloaded and formatted in an Excel spreadsheet. Note that while this notebook illustrates methods for cleaning and sub-sampling the dataset, it may be easier to simply clean the data in the spreadsheet.\n",
    "\n",
    "Either way, when data are read, it is usually helpful to read the date-time data into a Pandas date-time format. A challenge can occur when importing data that has dates formatted according to the European standard, with dates listed as YYYY-DD-MM. In this case, data can be imported using the \"dayfirst\" argument. If importing data in YYYY-MM-DD format, this argument is not needed.  \n",
    "\n",
    "Note that if your dataset has column names that differ from those used here, please adjust the snippets accordingtly.  For examply, you should change ['When'] to whatever name you used in your spreadsheet for the date-time column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ExampleRainData.xlsx')\n",
    "df['When'] = pd.to_datetime(df['When'],dayfirst=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334c3fc",
   "metadata": {},
   "source": [
    "### Set the index\n",
    "Graphing in Pandas is easiest if the index is set to the date-time column. Again, change the string 'When' to whatever is being used to represent your date-time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89291ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('When')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8ded0",
   "metadata": {},
   "source": [
    "### Make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2865520",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax = plt.subplots()\n",
    "df.plot(y='total', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83375e7",
   "metadata": {},
   "source": [
    "In the above, several days are plotted before the main storm event.  It can be helpful to re-sample just the data from the 28th of February, when the total count was 22.  For this, we can reset the value of the count to a new total representing the total precipitation AFTER midnight on the 28th of February."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e7322",
   "metadata": {},
   "source": [
    "### Reset the count to the value on February 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['newtotal']=df['total']-22\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff3f18",
   "metadata": {},
   "source": [
    "### Drop all the regular updates\n",
    "The original dataset includes many lines of data when no precipitation occurred but the device simply posted a regular status update. For analysis, we do not care about these regular updates. We only care about the lines where the bucket tip occurred.  This is only the case where the reset_cause variable was equal to 1. Here we create a new filtered data frame representing only the data associated with that cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c997af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['reset_cause'] == 1]\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263b07b",
   "metadata": {},
   "source": [
    "Now any data that did not have a reset cause of 1 should have been removed.\n",
    "\n",
    "### Select a range of dates\n",
    "Our graph will be nicer if we only start on the 28th. One way to accomplish this is to create a new dataframe that includes only the date range we care about. Note that in your dataset, this date range may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff4cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_subset = df_filtered.loc['2022-2-27':'2022-3-1'] \n",
    "display(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede8c8f",
   "metadata": {},
   "source": [
    "Because of the correction we applied earlier, the first \"newtotal\" in this dataframe really starts with zero.\n",
    "\n",
    "### Now plot this new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(1,1)\n",
    "ax = df_subset.plot(y=\"newtotal\", ax=ax)\n",
    "ax.set_ylabel(\"Accumulated Counts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866544e6",
   "metadata": {},
   "source": [
    "We can compare this to the previous, original total by adding a second line to the figure. Note that the syntax for adding additional datasets to the graph would be similar. Note that because of the offset we applied, the newtotal starts at zero, not at 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a30e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax = plt.subplots(1,1)\n",
    "df_subset.plot(y=\"total\", ax=ax)\n",
    "df_subset.plot(y=\"newtotal\", ax=ax)\n",
    "ax.set_ylabel(\"Accumulated Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea55580",
   "metadata": {},
   "source": [
    "### Resample to a higher resolution so that we can analyze the incremental counts\n",
    "\n",
    "Ultimately, we want to find the total number of tips that occur within a given period of time, probably computed on some regular interval. It's helpful if these intervals start at logical times, so here, we'll create a new dataframe that has data every single minute, starting at 0 seconds. The pandas resample() function allows this.  Here, if we resample with argument 'min', it samples every minute.  We could sample every 15 minutes using '15min' or every hour using 'h'.  Other options are documented in the pandas.dataframe.resample() help pages, which can easily be found with a simple web search.\n",
    "\n",
    "When we resample, we have to specify what method is used to fill in the number. We could find things like the sum, mean, median, and so on, of the variable that we are resampling.  For instance, if a dataframe included three rows, one for time t = 2 minutes, one for time t = 3 minutes, and one for time t = 7 minutes, and if the values of the variable x in these rows were 2, 3, and 1, respectively, the df.resample('5min').sum() function would result in a new dataframe with two rows, one representing time 0, and one representing time 5.  The values in these rows would be 5 (the sum of 2 and 3) and 1 (the only value in the original dataframe that appears during the second five-minute interval). In our case, we don't want to sum our counts, we just want the value of the count valid at the beginning of each minute of our deployment. The \"Ffill\" method (which stands for forward fill) allows us to do this by simply picking the value of the total that was present in our original dataframe for the period immediately before each minute we are considering in the new, resampled dataframe.   \n",
    "\n",
    "#### Ffill to minutely totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341fc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_minutely = pd.DataFrame()\n",
    "df_minutely['total']=df_subset['newtotal'].resample('min').ffill()\n",
    "display(df_minutely)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9ab53",
   "metadata": {},
   "source": [
    "In the above, the original dataframe did not begin until after 4:35:00, so the first number in the resampled dataframe is \"NaN\", or not a number.  Then, the first count (0) is used to fill in the values for 04:36:00 and 04:37:00. The total became 3 in the original dataframe at 04:37:07, so this value is used to fill in the total count at 04:38:00, and so on.\n",
    "\n",
    "### Find amount of precipitation in previous periods.\n",
    "Our goal in this assignment is to find out the maximum precipitation in 15-minute and 1-hour periods.  Here, we can compute how much precipitation we had in the previous 15 minutes or in the previous hour by simply subtracting the total precipitation we tabulated \"n\" rows earlier using the Pandas .shift(n) function.  The df.shift(n) function returns the value n rows earlier in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minutely['last60min']=df_minutely['total']-df_minutely['total'].shift(60)\n",
    "df_minutely['last15min']=df_minutely['total']-df_minutely['total'].shift(15)\n",
    "df_minutely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1303f",
   "metadata": {},
   "source": [
    "We now have data that gives us the amount of precipitation occuring in each 15-minute and each 1-hour period, starting at any minute during the deployment.  We have NaN values for the first few rows because it's not possible to shift earlier than the beginning of the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ff188",
   "metadata": {},
   "source": [
    "### Downsample on even hours\n",
    "While what we have done so far should be enough to address the lab assignment, it might still be nice to compute the incremental rainfall totals for time intervals that start at logical points in time (e.g., for hours that start on the our).  We can accomplish this by resampling the previous minultely data onto new, regularly spaced intervals. For this, we'll want to select the very first value in the resampling period, which will present the cumulative count valid at the beginning of the interval. We can then easily compute the amount of rainfall that occurred between this time and the next time interval (the so-called \"incremental rainfall\") by shifting a single row down and subtracting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly= pd.DataFrame()\n",
    "df_hourly['total']=df_minutely['total'].resample('h').first()\n",
    "df_hourly['incremental']=df_hourly['total'].shift(-1)-df_hourly['total']\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c216c",
   "metadata": {},
   "source": [
    "### Plot hourly incremental totals\n",
    "We can now create a simple bar plot to represent the incremental totals.  We are labeling them in real units of 1/100th of an inch because each tip of the gage represents 1/100th of an inch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d6a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig4,ax = plt.subplots(1,1)\n",
    "ax.set_ylabel(\"incremental depth (in/100)\")\n",
    "df_hourly.plot(y='incremental', kind='bar', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5b532",
   "metadata": {},
   "source": [
    "The x-axis labels are not particularly helpful here, but we can clean this up as by defining a tick format. We do this by creating an array of strings that we use as labels.  The strings just show the hour, then the minute.  These strings are then placed on each tick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f662f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "ticklabels = [item.strftime('%H:%M') for item in df_hourly.index]\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))\n",
    "fig4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24913702",
   "metadata": {},
   "source": [
    "Note the more logical ticks now on the figure.\n",
    "\n",
    "### Downsample to even 15-minute periods\n",
    "\n",
    "We now compute 15-minute incremental totals for time increments of 15-minutes that occur on the quarter-hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76291c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15minutely= pd.DataFrame()\n",
    "df_15minutely['total']=df_minutely['total'].resample('15min').first()\n",
    "df_15minutely['incremental']=df_15minutely['total'].shift(-1)-df_15minutely['total']\n",
    "df_15minutely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc7ca3",
   "metadata": {},
   "source": [
    "### Plot 15 minute incremental totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409fb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax = plt.subplots(1,1)\n",
    "df_15minutely.plot(y='incremental', kind='bar', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe91fff",
   "metadata": {},
   "source": [
    "The x-axis labels still need some help.  The following code fixes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "ax=df_15minutely.plot(y='incremental',kind='bar', stacked=True)\n",
    "ticklabels = ['']*len(df_15minutely.index)\n",
    "ticklabels[::4] = [item.strftime('%H:%M') for item in df_15minutely.index[::4]]\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))\n",
    "ax.set_ylabel(\"incremental depth (in/100)\")\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84645aff",
   "metadata": {},
   "source": [
    "Note that the above graph represents counts per quarter hour, so these numbers are quite a bit lower than the counts computed for the hour-long intervals. It is easier to compare these numbers if we plot intensity ${i}$, in inches per hour, rather than simple counts.  Intensity is defined as the rainfall depth ${\\Delta P}$ divided by the time interval ${\\Delta t}$ it fell within:  \n",
    "\n",
    "$$i=\\frac{\\Delta P}{\\Delta t}$$\n",
    "\n",
    "with $\\Delta t$ = 15 min = 0.25 hr, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15minutely['intensity']=df_15minutely['incremental']/0.25/100\n",
    "\n",
    "ax=df_15minutely.plot(y='intensity',kind='bar', stacked=True)\n",
    "ticklabels = ['']*len(df_15minutely.index)\n",
    "ticklabels[::4] = [item.strftime('%H:%M') for item in df_15minutely.index[::4]]\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))\n",
    "ax.set_ylabel(\"intensity (in/hr)\")\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393050b9-b103-42fe-8a2c-283dfc0419dc",
   "metadata": {},
   "source": [
    "You can now find the maximum intensity over these 15-minute intervals using the pandas max() function, which returns the maximum value of a colume, and the idxmax() function, which returns the index (for us, the date/time stamp) of the first instance of the maximum value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60df112-7564-4045-84a5-34f3f7ffdf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = df_15minutely['intensity'].max()\n",
    "time_of_max_i = df_15minutely['intensity'].idxmax()\n",
    "\n",
    "print(f'Maximum intensity = {max_i} in/hr for period beginning at t = {time_of_max_i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
